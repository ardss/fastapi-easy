# ğŸ”¬ æ·±å±‚æ¬¡ä»£ç æ½œåœ¨é—®é¢˜åˆ†æ

**åˆ†ææ—¥æœŸ**: 2025-11-29  
**åˆ†ææ·±åº¦**: ä»£ç çº§åˆ«  
**åˆ†æèŒƒå›´**: æ ¸å¿ƒè¿ç§»å¼•æ“æ¨¡å—

---

## ğŸš¨ ä¸¥é‡æ½œåœ¨é—®é¢˜

### 1. åˆ†å¸ƒå¼é” - è¿æ¥æ³„æ¼é£é™©

**ä½ç½®**: `distributed_lock.py` (PostgresLockProvider, MySQLLockProvider)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 56-60)
with self.engine.connect() as conn:
    result = conn.execute(
        text(f"SELECT pg_try_advisory_lock({self.lock_id})")
    )
    locked = result.scalar()
```

**æ½œåœ¨é£é™©** ğŸ”´ **é«˜**:
- è¿æ¥åœ¨å¾ªç¯ä¸­åå¤åˆ›å»ºå’Œé”€æ¯
- å¦‚æœè·å–é”å¤±è´¥ï¼Œä¼šåœ¨å¾ªç¯ä¸­åˆ›å»ºå¤šä¸ªè¿æ¥
- è¿æ¥æ± å¯èƒ½è€—å°½ (å°¤å…¶æ˜¯åœ¨é«˜å¹¶å‘åœºæ™¯)
- æ²¡æœ‰è¿æ¥è¶…æ—¶é…ç½®

**å½±å“**:
- é•¿æ—¶é—´è¿è¡Œæ—¶å¯èƒ½å¯¼è‡´è¿æ¥æ± è€—å°½
- å…¶ä»–æ“ä½œæ— æ³•è·å–æ•°æ®åº“è¿æ¥
- åº”ç”¨å¯èƒ½æŒ‚èµ·

**ä¿®å¤å»ºè®®**:
```python
# æ”¹è¿›æ–¹æ¡ˆ
async def acquire(self, timeout: int = 30) -> bool:
    start_time = time.time()
    conn = None
    try:
        # å¤ç”¨å•ä¸ªè¿æ¥
        conn = self.engine.connect()
        while time.time() - start_time < timeout:
            try:
                result = conn.execute(
                    text(f"SELECT pg_try_advisory_lock({self.lock_id})")
                )
                if result.scalar():
                    self.acquired = True
                    self._connection = conn  # ä¿å­˜è¿æ¥
                    return True
                await asyncio.sleep(0.1)
            except Exception as e:
                logger.error(f"Error: {e}")
                return False
        return False
    finally:
        if conn and not self.acquired:
            conn.close()
```

---

### 2. æ–‡ä»¶é” - ç«æ€æ¡ä»¶

**ä½ç½®**: `distributed_lock.py` (FileLockProvider)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 181-186)
fd = os.open(
    self.lock_file,
    os.O_CREAT | os.O_EXCL | os.O_WRONLY,
    0o644,
)
os.close(fd)
```

**æ½œåœ¨é£é™©** ğŸ”´ **é«˜**:
- æ–‡ä»¶åˆ›å»ºåç«‹å³å…³é—­ï¼Œä½†æ²¡æœ‰å†™å…¥è¿›ç¨‹ID
- å…¶ä»–è¿›ç¨‹æ— æ³•åˆ¤æ–­é”æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
- å¦‚æœè¿›ç¨‹å¼‚å¸¸é€€å‡ºï¼Œé”æ–‡ä»¶æ— æ³•è‡ªåŠ¨æ¸…ç†
- å¤šä¸ªè¿›ç¨‹å¯èƒ½åŒæ—¶å°è¯•åˆ é™¤åŒä¸€ä¸ªé”æ–‡ä»¶

**å½±å“**:
- å­¤ç«‹çš„é”æ–‡ä»¶å¯¼è‡´æ°¸ä¹…æ­»é”
- æ— æ³•åˆ¤æ–­é”çš„æ‰€æœ‰è€…
- éœ€è¦æ‰‹åŠ¨æ¸…ç†

**ä¿®å¤å»ºè®®**:
```python
# æ”¹è¿›æ–¹æ¡ˆ
async def acquire(self, timeout: int = 30) -> bool:
    start_time = time.time()
    while time.time() - start_time < timeout:
        try:
            fd = os.open(
                self.lock_file,
                os.O_CREAT | os.O_EXCL | os.O_WRONLY,
                0o644,
            )
            # å†™å…¥è¿›ç¨‹IDå’Œæ—¶é—´æˆ³
            os.write(fd, f"{os.getpid()}:{time.time()}".encode())
            os.close(fd)
            self.acquired = True
            self._pid = os.getpid()
            return True
        except FileExistsError:
            # æ£€æŸ¥é”æ˜¯å¦è¿‡æœŸ
            try:
                with open(self.lock_file, 'r') as f:
                    content = f.read()
                    pid, timestamp = content.split(':')
                    if time.time() - float(timestamp) > timeout * 2:
                        # é”å·²è¿‡æœŸï¼Œå¼ºåˆ¶åˆ é™¤
                        os.remove(self.lock_file)
                        continue
            except:
                pass
            await asyncio.sleep(0.1)
    return False
```

---

### 3. Schema æ£€æµ‹ - å¼‚æ­¥/åŒæ­¥æ··åˆé—®é¢˜

**ä½ç½®**: `detector.py` (detect_changes)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 21-24)
async def detect_changes(self) -> List[SchemaChange]:
    inspector = await asyncio.to_thread(inspect, self.engine)
    # ... åç»­éƒ½æ˜¯åŒæ­¥ä»£ç 
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- åªæœ‰ç¬¬ä¸€è¡Œæ˜¯å¼‚æ­¥ï¼Œå…¶ä½™éƒ½æ˜¯åŒæ­¥
- åœ¨å¾ªç¯ä¸­è°ƒç”¨åŒæ­¥çš„ `_analyze_add_column` ç­‰æ–¹æ³•
- å¦‚æœæœ‰å¤§é‡è¡¨/åˆ—ï¼Œä¼šé˜»å¡äº‹ä»¶å¾ªç¯
- æ²¡æœ‰è¿›åº¦æŠ¥å‘Šæˆ–è¶…æ—¶æ§åˆ¶

**å½±å“**:
- å¤§å‹æ•°æ®åº“çš„ Schema æ£€æµ‹å¯èƒ½å¯¼è‡´äº‹ä»¶å¾ªç¯é˜»å¡
- å…¶ä»–å¼‚æ­¥ä»»åŠ¡æ— æ³•æ‰§è¡Œ
- ç”¨æˆ·ç•Œé¢å¯èƒ½å†»ç»“

**ä¿®å¤å»ºè®®**:
```python
# æ”¹è¿›æ–¹æ¡ˆ
async def detect_changes(self) -> List[SchemaChange]:
    inspector = await asyncio.to_thread(inspect, self.engine)
    changes = []
    
    # å°†åŒæ­¥æ“ä½œåˆ†æ‰¹æ”¾å…¥çº¿ç¨‹æ± 
    tasks = []
    for table_name, table in self.metadata.tables.items():
        task = asyncio.to_thread(
            self._analyze_table,
            table_name, table, inspector
        )
        tasks.append(task)
    
    # å¹¶å‘æ‰§è¡Œ
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    for result in results:
        if isinstance(result, Exception):
            logger.error(f"Error analyzing table: {result}")
        else:
            changes.extend(result)
    
    return changes
```

---

### 4. è¿ç§»æ‰§è¡Œ - äº‹åŠ¡å¤„ç†ä¸å½“

**ä½ç½®**: `executor.py` (_execute_sql_sync)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 110-133)
def _execute_sql_sync(self, sql: str):
    has_transaction = any(keyword in sql.upper() for keyword in ['BEGIN TRANSACTION', 'BEGIN;', 'COMMIT'])
    
    if has_transaction:
        with self.engine.connect() as conn:
            statements = self._split_sql_statements(sql)
            for statement in statements:
                if statement and not statement.upper().startswith('BEGIN') and not statement.upper().startswith('COMMIT'):
                    conn.execute(text(statement))
            conn.commit()
```

**æ½œåœ¨é£é™©** ğŸ”´ **é«˜**:
- æ‰‹åŠ¨æäº¤äº‹åŠ¡å¯èƒ½å¯¼è‡´é‡å¤æäº¤
- å¦‚æœ SQL åŒ…å« BEGIN ä½†ä¸åŒ…å« COMMITï¼Œä¼šå¯¼è‡´äº‹åŠ¡æ³„æ¼
- æ²¡æœ‰å›æ»šæœºåˆ¶
- é”™è¯¯å¤„ç†ä¸å®Œå–„

**å½±å“**:
- æ•°æ®åº“è¿æ¥æ³„æ¼
- é•¿æ—¶é—´è¿è¡Œçš„äº‹åŠ¡é”å®šè¡¨
- æ•°æ®ä¸ä¸€è‡´

**ä¿®å¤å»ºè®®**:
```python
# æ”¹è¿›æ–¹æ¡ˆ
def _execute_sql_sync(self, sql: str):
    try:
        with self.engine.begin() as conn:  # è‡ªåŠ¨å¤„ç†äº‹åŠ¡
            statements = self._split_sql_statements(sql)
            for statement in statements:
                if statement:
                    logger.debug(f"Executing: {statement[:100]}...")
                    conn.execute(text(statement))
            # è‡ªåŠ¨æäº¤
    except Exception as e:
        logger.error(f"Migration failed: {e}")
        # è‡ªåŠ¨å›æ»š
        raise
```

---

### 5. Schema ç¼“å­˜ - Redis è¿æ¥ç®¡ç†

**ä½ç½®**: `schema_cache.py` (RedisSchemaCacheProvider)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 122-134)
def _initialize(self):
    try:
        import redis
        self.redis_client = redis.from_url(self.redis_url)
        self.redis_client.ping()
    except ImportError:
        logger.warning("Redis not installed...")
    except Exception as e:
        logger.warning(f"Failed to connect to Redis: {e}")
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- æ²¡æœ‰è¿æ¥æ± é…ç½®
- æ²¡æœ‰é‡è¯•æœºåˆ¶
- æ²¡æœ‰è¶…æ—¶è®¾ç½®
- åˆå§‹åŒ–å¤±è´¥æ—¶æ²¡æœ‰é™çº§æ–¹æ¡ˆ

**å½±å“**:
- å•ä¸ª Redis è¿æ¥å¯èƒ½å¯¼è‡´æ€§èƒ½é—®é¢˜
- ç½‘ç»œæŠ–åŠ¨æ—¶æ— æ³•è‡ªåŠ¨æ¢å¤
- ç¼“å­˜å®Œå…¨ä¸å¯ç”¨

**ä¿®å¤å»ºè®®**:
```python
# æ”¹è¿›æ–¹æ¡ˆ
def _initialize(self):
    try:
        import redis
        self.redis_client = redis.from_url(
            self.redis_url,
            decode_responses=True,
            socket_connect_timeout=5,
            socket_keepalive=True,
            socket_keepalive_options={
                1: 1,  # TCP_KEEPIDLE
                2: 3,  # TCP_KEEPINTVL
                3: 5,  # TCP_KEEPCNT
            },
            connection_pool_kwargs={
                'max_connections': 10,
                'retry_on_timeout': True,
            }
        )
        self.redis_client.ping()
    except ImportError:
        logger.warning("Redis not installed, using file cache")
        self.redis_client = None
    except Exception as e:
        logger.warning(f"Redis unavailable: {e}, using file cache")
        self.redis_client = None
```

---

## âš ï¸ ä¸­ç­‰æ½œåœ¨é—®é¢˜

### 6. è¿ç§»å­˜å‚¨ - SQL æ³¨å…¥é£é™©

**ä½ç½®**: `storage.py` (record_migration)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 45-48)
conn.execute(
    text(f"""
        INSERT INTO {self.TABLE_NAME} 
        (version, description, applied_at, rollback_sql, risk_level, status)
        VALUES (:version, :description, :applied_at, :rollback_sql, :risk_level, 'applied')
    """),
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- è™½ç„¶ä½¿ç”¨äº†å‚æ•°åŒ–æŸ¥è¯¢ï¼Œä½†è¡¨åæ˜¯ç¡¬ç¼–ç çš„
- å¦‚æœè¡¨åæ¥è‡ªç”¨æˆ·è¾“å…¥ä¼šæœ‰ SQL æ³¨å…¥é£é™©
- æ²¡æœ‰éªŒè¯è¾“å…¥é•¿åº¦

**å½±å“**:
- æ½œåœ¨çš„ SQL æ³¨å…¥æ”»å‡»
- æ•°æ®åº“å®‰å…¨æ€§é™ä½

**ä¿®å¤å»ºè®®**:
```python
# æ”¹è¿›æ–¹æ¡ˆ
def record_migration(self, version: str, description: str, 
                    rollback_sql: str, risk_level: str):
    # éªŒè¯è¾“å…¥
    if len(version) > 100 or len(description) > 500:
        raise ValueError("Input too long")
    
    try:
        with self.engine.begin() as conn:
            # ä½¿ç”¨ insert() è€Œä¸æ˜¯ text()
            stmt = self.table.insert().values(
                version=version,
                description=description,
                applied_at=datetime.now(),
                rollback_sql=rollback_sql,
                risk_level=risk_level,
                status='applied'
            )
            conn.execute(stmt)
```

---

### 7. Hook ç³»ç»Ÿ - é”™è¯¯éš”ç¦»ä¸å®Œå–„

**ä½ç½®**: `hooks.py` (execute_hooks)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 111-131)
for hook in hooks:
    try:
        if hook.is_async:
            result = await hook.callback(context)
        else:
            result = hook.callback(context)
        results[hook.name] = result
    except Exception as e:
        logger.error(f"Error executing hook {hook.name}: {e}")
        results[hook.name] = {"error": str(e)}
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- åŒæ­¥ Hook åœ¨å¼‚æ­¥å‡½æ•°ä¸­è°ƒç”¨ï¼Œå¯èƒ½é˜»å¡äº‹ä»¶å¾ªç¯
- æ²¡æœ‰è¶…æ—¶æ§åˆ¶
- æ²¡æœ‰èµ„æºæ¸…ç†æœºåˆ¶

**å½±å“**:
- é•¿æ—¶é—´è¿è¡Œçš„ Hook ä¼šé˜»å¡è¿ç§»
- äº‹ä»¶å¾ªç¯è¢«é˜»å¡
- å†…å­˜æ³„æ¼

**ä¿®å¤å»ºè®®**:
```python
# æ”¹è¿›æ–¹æ¡ˆ
async def execute_hooks(self, trigger, version=None, context=None):
    if context is None:
        context = {}
    
    hooks = (
        self.get_hooks_for_version(version, trigger)
        if version else self.get_hooks(trigger)
    )
    
    results = {}
    
    for hook in hooks:
        try:
            logger.debug(f"Executing hook: {hook.name}")
            
            if hook.is_async:
                # å¼‚æ­¥ Hook æœ‰è¶…æ—¶
                result = await asyncio.wait_for(
                    hook.callback(context),
                    timeout=30
                )
            else:
                # åŒæ­¥ Hook åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ
                result = await asyncio.to_thread(
                    hook.callback,
                    context
                )
            
            results[hook.name] = result
            
        except asyncio.TimeoutError:
            logger.error(f"Hook {hook.name} timed out")
            results[hook.name] = {"error": "Timeout"}
        except Exception as e:
            logger.error(f"Error executing hook {hook.name}: {e}")
            results[hook.name] = {"error": str(e)}
    
    self._hook_results[trigger.value] = results
    return results
```

---

### 8. é£é™©è¯„ä¼° - è§„åˆ™æ¡ä»¶å¼‚å¸¸

**ä½ç½®**: `risk_engine.py` (assess)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 156-166)
for rule in self.custom_rules:
    try:
        if rule.condition(change):
            return rule.risk_level
    except Exception as e:
        logger.warning(f"Error evaluating rule {rule.name}: {e}")
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- è§„åˆ™æ¡ä»¶å¼‚å¸¸è¢«åæ‰ï¼Œå¯èƒ½å¯¼è‡´è§„åˆ™å¤±æ•ˆ
- æ²¡æœ‰æ—¥å¿—è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
- æ²¡æœ‰è§„åˆ™éªŒè¯æœºåˆ¶

**å½±å“**:
- é£é™©è¯„ä¼°ä¸å‡†ç¡®
- éš¾ä»¥è°ƒè¯•è§„åˆ™é—®é¢˜

**ä¿®å¤å»ºè®®**:
```python
# æ”¹è¿›æ–¹æ¡ˆ
def assess(self, change: SchemaChange) -> RiskLevel:
    for rule in self.custom_rules:
        try:
            if rule.condition(change):
                logger.info(f"Risk rule matched: {rule.name}")
                return rule.risk_level
        except Exception as e:
            logger.error(
                f"Error evaluating rule {rule.name}: {e}",
                exc_info=True  # è®°å½•å®Œæ•´å †æ ˆ
            )
            # è§„åˆ™å¼‚å¸¸æ—¶ä½¿ç”¨ä¿å®ˆçš„é£é™©ç­‰çº§
            return RiskLevel.HIGH
    
    return self._assess_by_type(change)
```

---

## ğŸ’¡ ä½ä¼˜å…ˆçº§é—®é¢˜

### 9. å†…å­˜æ³„æ¼é£é™© - ä¸´æ—¶å¯¹è±¡

**ä½ç½®**: `detector.py` (å¤šå¤„)

**é—®é¢˜**:
- åˆ›å»ºå¤§é‡ä¸´æ—¶ SchemaChange å¯¹è±¡ç”¨äºé£é™©è¯„ä¼°
- æ²¡æœ‰åŠæ—¶æ¸…ç†

**ä¿®å¤**:
```python
# æ”¹è¿›æ–¹æ¡ˆ - ä½¿ç”¨å¯¹è±¡æ± æˆ–å·¥å‚æ¨¡å¼
class SchemaChangeFactory:
    @staticmethod
    def create_temp_change(type_, table, **kwargs):
        # åˆ›å»ºä¸´æ—¶å¯¹è±¡
        return SchemaChange(
            type=type_,
            table=table,
            risk_level=RiskLevel.SAFE,
            description="",
            **kwargs
        )
```

---

### 10. æ—¥å¿—çº§åˆ«ä¸å½“

**ä½ç½®**: å¤šä¸ªæ–‡ä»¶

**é—®é¢˜**:
- è¿‡å¤šçš„ DEBUG æ—¥å¿—å¯èƒ½å½±å“æ€§èƒ½
- æ²¡æœ‰æ—¥å¿—é‡‡æ ·æœºåˆ¶

**ä¿®å¤**:
```python
# æ”¹è¿›æ–¹æ¡ˆ
if logger.isEnabledFor(logging.DEBUG):
    logger.debug(f"Expensive operation: {expensive_calculation()}")
```

---

## ğŸ“Š é—®é¢˜ä¼˜å…ˆçº§çŸ©é˜µ

```
ä¸¥é‡æ€§ vs å½±å“èŒƒå›´

        é«˜å½±å“
          â†‘
    1 â”Œâ”€â”€â”€â”€â”€â” 2
      â”‚ ğŸ”´  â”‚ ğŸ”´
      â”‚ 1,2 â”‚ 3,4
    ä¸­â”œâ”€â”€â”€â”€â”€â”¤
      â”‚ ğŸŸ¡  â”‚ ğŸŸ¡
      â”‚ 6,7 â”‚ 5,8
    ä½â””â”€â”€â”€â”€â”€â”˜
      ä½    é«˜
      â† æ¦‚ç‡ â†’
```

**ä¼˜å…ˆçº§æ’åº**:
1. ğŸ”´ **ç«‹å³ä¿®å¤** (P0): é—®é¢˜ 1, 2, 4
2. ğŸŸ¡ **æœ¬å‘¨ä¿®å¤** (P1): é—®é¢˜ 3, 5, 6, 7
3. ğŸŸ¢ **åç»­æ”¹è¿›** (P2): é—®é¢˜ 8, 9, 10

---

## ğŸ”§ ä¿®å¤è®¡åˆ’

### ç¬¬ä¸€é˜¶æ®µ (ç«‹å³)
- [ ] ä¿®å¤åˆ†å¸ƒå¼é”è¿æ¥æ³„æ¼
- [ ] ä¿®å¤æ–‡ä»¶é”ç«æ€æ¡ä»¶
- [ ] ä¿®å¤è¿ç§»æ‰§è¡Œäº‹åŠ¡å¤„ç†

### ç¬¬äºŒé˜¶æ®µ (æœ¬å‘¨)
- [ ] ä¼˜åŒ– Schema æ£€æµ‹å¼‚æ­¥æ€§èƒ½
- [ ] æ”¹è¿› Redis ç¼“å­˜è¿æ¥ç®¡ç†
- [ ] å¢å¼º Hook ç³»ç»Ÿè¶…æ—¶æ§åˆ¶

### ç¬¬ä¸‰é˜¶æ®µ (åç»­)
- [ ] æ·»åŠ  SQL æ³¨å…¥é˜²æŠ¤
- [ ] æ”¹è¿›é”™è¯¯éš”ç¦»æœºåˆ¶
- [ ] ä¼˜åŒ–å†…å­˜ä½¿ç”¨

---

## âœ… éªŒè¯æ¸…å•

ä¿®å¤åéœ€è¦éªŒè¯:
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] æ²¡æœ‰è¿æ¥æ³„æ¼
- [ ] æ²¡æœ‰æ­»é”
- [ ] æ€§èƒ½æ— é€€åŒ–
- [ ] æ—¥å¿—æ¸…æ™°

---

**åˆ†æå®Œæˆ**: 2025-11-29  
**å»ºè®®è¡ŒåŠ¨**: ç«‹å³ä¿®å¤ P0 é—®é¢˜ï¼Œæœ¬å‘¨å®Œæˆ P1 é—®é¢˜
