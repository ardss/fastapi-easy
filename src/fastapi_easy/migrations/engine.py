import asyncio
import logging
from typing import Optional

from sqlalchemy import Engine

from .detector import SchemaDetector
from .distributed_lock import get_lock_provider
from .executor import MigrationExecutor
from .generator import MigrationGenerator
from .hooks import HookTrigger, get_hook_registry
from .storage import MigrationStorage
from .types import ExecutionMode, MigrationPlan, OperationResult

logger = logging.getLogger(__name__)

class MigrationEngine:
    """The main entry point for the migration system"""
    
    def __init__(
        self,
        engine: Engine,
        metadata,
        mode: ExecutionMode = ExecutionMode.SAFE
    ):
        """Initialize the migration engine

        Args:
            engine: SQLAlchemy engine
            metadata: SQLAlchemy metadata
            mode: Execution mode (SAFE, DRY_RUN, FORCE)
        """
        if not isinstance(mode, ExecutionMode):
            raise TypeError(
                f"mode must be ExecutionMode enum, "
                f"got {type(mode).__name__}"
            )

        self.engine = engine
        self.metadata = metadata
        self.mode = mode
        self.detector = SchemaDetector(engine, metadata)
        self.generator = MigrationGenerator(engine)
        self.executor = MigrationExecutor(engine)
        self.storage = MigrationStorage(engine)
        self.lock = get_lock_provider(engine)

        # Initialize storage
        self.storage.initialize()

    async def auto_migrate(self) -> MigrationPlan:
        """Automatically detect and apply migrations"""

        # 1. Acquire Lock
        logger.info("è·å–è¿ç§»é”...")
        if not await self.lock.acquire():
            logger.warning("æ— æ³•è·å–é”ï¼Œå‡è®¾å¦ä¸€ä¸ªå®ä¾‹æ­£åœ¨è¿ç§»")
            return MigrationPlan(migrations=[], status="locked")

        try:
            # 2. Execute BEFORE_DDL Hook
            hook_registry = get_hook_registry()
            await hook_registry.execute_hooks(
                HookTrigger.BEFORE_DDL,
                context={"mode": self.mode}
            )

            logger.info("æ£€æµ‹ Schema å˜æ›´...")

            # 3. Detect changes
            changes = await self.detector.detect_changes()

            if not changes:
                logger.info("Schema å·²åŒæ­¥")
                return MigrationPlan(migrations=[], status="up_to_date")

            logger.info(f"æ£€æµ‹åˆ° {len(changes)} ä¸ªå˜æ›´")

            # 4. Generate plan
            plan = self.generator.generate_plan(changes)

            # 5. Log plan
            for migration in plan.migrations:
                logger.info(
                    f"  [{migration.risk_level.value}] "
                    f"{migration.description}"
                )

            # 6. Execute migrations
            logger.info(f"æ‰§è¡Œè¿ç§» (æ¨¡å¼: {self.mode})")
            plan, executed_migrations = await self.executor.execute_plan(
                plan, mode=self.mode
            )

            # 7. Execute AFTER_DDL Hook
            await hook_registry.execute_hooks(
                HookTrigger.AFTER_DDL,
                context={
                    "plan": plan,
                    "executed": executed_migrations,
                    "status": plan.status
                }
            )

            # 8. Record successfully executed migrations
            for migration in executed_migrations:
                self.storage.record_migration(
                    version=migration.version,
                    description=migration.description,
                    rollback_sql=migration.downgrade_sql,
                    risk_level=migration.risk_level.value
                )

            logger.info(f"è¿ç§»å®Œæˆ: {plan.status}")
            return plan

        except Exception as e:
            error_msg = str(e)
            logger.error(
                f"è¿ç§»å¤±è´¥: {error_msg}\n"
                f"è°ƒè¯•æ­¥éª¤:\n"
                f"  1. æ£€æŸ¥æ•°æ®åº“è¿æ¥\n"
                f"  2. æŸ¥çœ‹è¯¦ç»†æ—¥å¿—: è®¾ç½® LOG_LEVEL=DEBUG\n"
                f"  3. è¿è¡Œ dry-run æ¨¡å¼\n"
                f"  4. æŸ¥çœ‹å®Œæ•´é”™è¯¯: {error_msg}",
                exc_info=True
            )
            raise
        finally:
            # 7. Release Lock with retry
            logger.info("é‡Šæ”¾è¿ç§»é”...")
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    await self.lock.release()
                    logger.info("è¿ç§»é”å·²é‡Šæ”¾")
                    break
                except Exception as e:
                    if attempt < max_retries - 1:
                        logger.warning(
                            f"é”é‡Šæ”¾å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}), "
                            f"é‡è¯•ä¸­..."
                        )
                        await asyncio.sleep(1)
                    else:
                        logger.error(
                            f"é”é‡Šæ”¾å¤±è´¥: {e}\n"
                            f"æ‚¨å¯èƒ½éœ€è¦æ‰‹åŠ¨æ¸…ç†é”æ–‡ä»¶ã€‚\n"
                            f"è§£å†³æ–¹æ¡ˆ:\n"
                            f"  1. æ£€æŸ¥é”æ–‡ä»¶: .fastapi_easy_migration.lock\n"
                            f"  2. æ‰‹åŠ¨åˆ é™¤: rm .fastapi_easy_migration.lock\n"
                            f"  3. é‡æ–°è¿è¡Œè¿ç§»",
                            exc_info=True
                        )
    
    def get_history(self, max_items: int = 10):
        """Get migration history
        
        Args:
            max_items: Maximum number of migration records to return
        """
        return self.storage.get_migration_history(limit=max_items)
    
    async def rollback(self, steps: int = 1, continue_on_error: bool = False) -> OperationResult:
        """
        å›æ»šæŒ‡å®šæ•°é‡çš„è¿ç§»
        
        Args:
            steps: è¦å›æ»šçš„è¿ç§»æ•°é‡
            continue_on_error: æ˜¯å¦åœ¨é”™è¯¯æ—¶ç»§ç»­å›æ»š
        
        Returns:
            OperationResult with:
                success: bool
                data: {
                    'rolled_back': int,  # æˆåŠŸå›æ»šçš„æ•°é‡
                    'failed': int,       # å¤±è´¥çš„æ•°é‡
                }
                errors: [...]  # é”™è¯¯åˆ—è¡¨
        """
        result = OperationResult(success=False)
        
        # éªŒè¯å‚æ•°
        if steps <= 0:
            logger.error("âŒ å›æ»šæ­¥æ•°å¿…é¡»å¤§äº 0")
            result.add_error("å›æ»šæ­¥æ•°å¿…é¡»å¤§äº 0")
            return result
        
        # è·å–è¿ç§»å†å²
        history = self.storage.get_migration_history(limit=steps)
        
        if not history:
            logger.warning("âš ï¸ æ²¡æœ‰å¯å›æ»šçš„è¿ç§»")
            result.add_error("æ²¡æœ‰å¯å›æ»šçš„è¿ç§»")
            return result
        
        # è·å–é”
        logger.info(f"ğŸ”’ è·å–è¿ç§»é”...")
        if not await self.lock.acquire():
            logger.warning("â³ æ— æ³•è·å–é”ï¼Œå‡è®¾å¦ä¸€ä¸ªå®ä¾‹æ­£åœ¨è¿ç§»")
            result.add_error("æ— æ³•è·å–è¿ç§»é”")
            return result
        
        try:
            logger.info(f"â®ï¸ å‡†å¤‡å›æ»š {len(history)} ä¸ªè¿ç§»...")
            
            # æŒ‰ç›¸åé¡ºåºæ‰§è¡Œå›æ»š
            for record in reversed(history):
                version = record.get("version")
                description = record.get("description", "Unknown")
                rollback_sql = record.get("rollback_sql")
                
                if not rollback_sql:
                    logger.warning(f"âš ï¸ è¿ç§» {version} æ²¡æœ‰å›æ»š SQLï¼Œè·³è¿‡")
                    continue
                
                try:
                    logger.info(f"  å›æ»š {version}: {description}")
                    
                    # æ‰§è¡Œå›æ»š SQL
                    from sqlalchemy import text
                    with self.engine.begin() as conn:
                        for statement in rollback_sql.split(";"):
                            statement = statement.strip()
                            if statement:
                                conn.execute(text(statement))
                    
                    logger.info(f"  âœ… æˆåŠŸå›æ»š {version}")
                    if result.data is None:
                        result.data = {'rolled_back': 0, 'failed': 0}
                    result.data['rolled_back'] += 1
                
                except Exception as e:
                    logger.error(f"  âŒ å›æ»š {version} å¤±è´¥: {e}")
                    if result.data is None:
                        result.data = {'rolled_back': 0, 'failed': 0}
                    result.data['failed'] += 1
                    result.add_error(f"{version}: {str(e)}")
                    
                    if not continue_on_error:
                        raise
                    else:
                        logger.warning(f"ç»§ç»­å›æ»šä¸‹ä¸€ä¸ªè¿ç§»...")
            
            if result.data is None:
                result.data = {'rolled_back': 0, 'failed': 0}
            result.success = result.data['failed'] == 0
            if result.success:
                logger.info(f"âœ… æˆåŠŸå›æ»š {result.data['rolled_back']} ä¸ªè¿ç§»")
            else:
                logger.warning(f"âš ï¸ å›æ»šå®Œæˆ: {result.data['rolled_back']} æˆåŠŸ, {result.data['failed']} å¤±è´¥")
            
            return result
        
        except Exception as e:
            logger.error(f"âŒ å›æ»šå¤±è´¥: {e}", exc_info=True)
            result.add_error(str(e))
            return result
        
        finally:
            # é‡Šæ”¾é” (å¸¦é‡è¯•æœºåˆ¶)
            logger.info("é‡Šæ”¾è¿ç§»é”...")
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    await self.lock.release()
                    logger.info("è¿ç§»é”å·²é‡Šæ”¾")
                    break
                except Exception as e:
                    if attempt < max_retries - 1:
                        logger.warning(
                            f"é”é‡Šæ”¾å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}), "
                            f"é‡è¯•ä¸­..."
                        )
                        await asyncio.sleep(1)
                    else:
                        logger.error(f"é”é‡Šæ”¾å¤±è´¥: {e}")
