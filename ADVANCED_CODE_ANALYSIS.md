# ğŸ”¬ é«˜çº§ä»£ç æ·±å±‚åˆ†æ - é—æ¼é—®é¢˜æ£€æŸ¥

**åˆ†ææ—¥æœŸ**: 2025-11-29  
**åˆ†ææ·±åº¦**: ä»£ç çº§åˆ« (é«˜çº§)  
**åˆ†æèŒƒå›´**: èµ„æºç®¡ç†ã€å¹¶å‘ã€æ€§èƒ½ã€æ•°æ®ä¸€è‡´æ€§

---

## ğŸš¨ æ–°å‘ç°çš„ä¸¥é‡é—®é¢˜

### 1. ç¼“å­˜å¹¶å‘è®¿é—® - çº¿ç¨‹ä¸å®‰å…¨

**ä½ç½®**: `schema_cache.py` (SchemaCacheManager)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 229-234)
self.stats = {
    "hits": 0,
    "misses": 0,
    "writes": 0,
    "deletes": 0,
}

# åœ¨ async æ–¹æ³•ä¸­ä¿®æ”¹ (line 246)
self.stats["hits"] += 1
```

**æ½œåœ¨é£é™©** ğŸ”´ **é«˜**:
- ç»Ÿè®¡æ•°æ®åœ¨å¹¶å‘è®¿é—®æ—¶ä¸å®‰å…¨
- å¤šä¸ªå¼‚æ­¥ä»»åŠ¡åŒæ—¶ä¿®æ”¹ stats ä¼šå¯¼è‡´æ•°æ®ä¸ä¸€è‡´
- æ²¡æœ‰é”ä¿æŠ¤

**å½±å“**:
- ç¼“å­˜ç»Ÿè®¡æ•°æ®ä¸å‡†ç¡®
- åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹æ•°æ®æŸå

**ä¿®å¤å»ºè®®**:
```python
import threading

class SchemaCacheManager:
    def __init__(self, ...):
        self.stats_lock = threading.Lock()
        self.stats = {...}
    
    async def get_cached_schema(self, ...):
        cached = await self.provider.get(cache_key)
        if cached:
            with self.stats_lock:
                self.stats["hits"] += 1
```

---

### 2. MySQL é” - è¿æ¥æ³„æ¼

**ä½ç½®**: `distributed_lock.py` (MySQLLockProvider)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 129-132)
with self.engine.connect() as conn:
    result = conn.execute(
        text(f"SELECT GET_LOCK('{self.lock_name}', {timeout})")
    )
    locked = result.scalar()
    
    if locked == 1:
        self.acquired = True
        # è¿æ¥åœ¨è¿™é‡Œè¢«å…³é—­ï¼
        return True
```

**æ½œåœ¨é£é™©** ğŸ”´ **é«˜**:
- MySQL GET_LOCK è·å–çš„é”ä¸è¿æ¥ç»‘å®š
- è¿æ¥å…³é—­åï¼Œé”è‡ªåŠ¨é‡Šæ”¾
- è¿™å¯¼è‡´é”ç«‹å³å¤±æ•ˆ

**å½±å“**:
- MySQL é”æ— æ³•æ­£å¸¸å·¥ä½œ
- å¤šä¸ªè¿›ç¨‹å¯èƒ½åŒæ—¶æ‰§è¡Œè¿ç§»
- æ•°æ®åº“å¯èƒ½è¢«ç ´å

**ä¿®å¤å»ºè®®**:
```python
class MySQLLockProvider(LockProvider):
    def __init__(self, engine: Engine, ...):
        self.engine = engine
        self.lock_name = lock_name
        self.acquired = False
        self._connection = None  # ä¿å­˜è¿æ¥
    
    async def acquire(self, timeout: int = 30) -> bool:
        try:
            conn = self.engine.connect()
            result = conn.execute(
                text(f"SELECT GET_LOCK('{self.lock_name}', {timeout})")
            )
            locked = result.scalar()
            
            if locked == 1:
                self.acquired = True
                self._connection = conn  # ä¿å­˜è¿æ¥
                return True
            else:
                conn.close()
                return False
        except Exception as e:
            logger.error(f"Error acquiring MySQL lock: {e}")
            return False
    
    async def release(self) -> bool:
        if not self.acquired or not self._connection:
            return False
        
        try:
            result = self._connection.execute(
                text(f"SELECT RELEASE_LOCK('{self.lock_name}')")
            )
            released = result.scalar()
            self.acquired = False
            return released == 1
        finally:
            if self._connection:
                self._connection.close()
                self._connection = None
```

---

### 3. æ–‡ä»¶ç¼“å­˜ - å¹¶å‘å†™å…¥å†²çª

**ä½ç½®**: `schema_cache.py` (FileSchemaCacheProvider)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 78-88)
async def set(self, key: str, value: Dict[str, Any]) -> bool:
    try:
        cache_file = self._get_cache_file(key)
        with open(cache_file, "w") as f:
            json.dump(value, f, indent=2)
        return True
    except Exception as e:
        logger.error(f"Error writing cache: {e}")
        return False
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- å¤šä¸ªè¿›ç¨‹åŒæ—¶å†™å…¥åŒä¸€ä¸ªç¼“å­˜æ–‡ä»¶
- æ²¡æœ‰åŸå­æ“ä½œä¿è¯
- æ–‡ä»¶å¯èƒ½è¢«éƒ¨åˆ†è¦†ç›–

**å½±å“**:
- ç¼“å­˜æ•°æ®æŸå
- è¯»å–åˆ°ä¸å®Œæ•´çš„ JSON

**ä¿®å¤å»ºè®®**:
```python
import tempfile

async def set(self, key: str, value: Dict[str, Any]) -> bool:
    try:
        cache_file = self._get_cache_file(key)
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ + åŸå­é‡å‘½å
        temp_fd, temp_path = tempfile.mkstemp(
            dir=self.cache_dir,
            suffix='.tmp'
        )
        try:
            with os.fdopen(temp_fd, 'w') as f:
                json.dump(value, f, indent=2)
            # åŸå­é‡å‘½å
            os.replace(temp_path, cache_file)
            return True
        except:
            os.unlink(temp_path)
            raise
    except Exception as e:
        logger.error(f"Error writing cache: {e}")
        return False
```

---

### 4. è¿ç§»å­˜å‚¨ - å¹¶å‘æ’å…¥å†²çª

**ä½ç½®**: `storage.py` (MigrationStorage)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 40-57)
def record_migration(self, version: str, ...):
    try:
        with self.engine.begin() as conn:
            conn.execute(
                text(f"""
                    INSERT INTO {self.TABLE_NAME} 
                    (version, description, ...)
                    VALUES (:version, :description, ...)
                """),
                {...}
            )
    except Exception as e:
        logger.error(f"Failed to record migration {version}: {e}")
        # ä¸æŠ›å‡ºå¼‚å¸¸ - è®°å½•å¤±è´¥è¢«åæ‰
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- å¦‚æœä¸¤ä¸ªè¿›ç¨‹åŒæ—¶æ‰§è¡Œç›¸åŒçš„è¿ç§»
- ä¼šå¯¼è‡´ UNIQUE çº¦æŸå†²çª
- é”™è¯¯è¢«åæ‰ï¼Œç”¨æˆ·ä¸çŸ¥é“å‘ç”Ÿäº†ä»€ä¹ˆ

**å½±å“**:
- è¿ç§»è®°å½•ä¸å®Œæ•´
- æ— æ³•è¿½è¸ªè¿ç§»å†å²
- éš¾ä»¥è°ƒè¯•é—®é¢˜

**ä¿®å¤å»ºè®®**:
```python
def record_migration(self, version: str, ...):
    try:
        with self.engine.begin() as conn:
            conn.execute(
                text(f"""
                    INSERT INTO {self.TABLE_NAME} 
                    (version, description, ...)
                    VALUES (:version, :description, ...)
                """),
                {...}
            )
        logger.info(f"ğŸ“ Recorded migration: {version}")
    except IntegrityError as e:
        # ç‰ˆæœ¬å·²å­˜åœ¨ - è¿™æ˜¯ä¸€ä¸ªé”™è¯¯
        logger.error(
            f"Migration {version} already recorded: {e}",
            exc_info=True
        )
        raise
    except Exception as e:
        logger.error(f"Failed to record migration {version}: {e}")
        raise
```

---

### 5. å¼•æ“åˆå§‹åŒ– - ç¼ºå°‘éªŒè¯

**ä½ç½®**: `engine.py` (MigrationEngine.__init__)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 18-37)
def __init__(
    self, 
    engine: Engine, 
    metadata,
    mode: str = "safe",
    auto_backup: bool = False
):
    self.engine = engine
    self.metadata = metadata
    self.mode = mode
    # æ²¡æœ‰éªŒè¯ mode çš„æœ‰æ•ˆæ€§
    # æ²¡æœ‰éªŒè¯ engine çš„è¿æ¥
    # æ²¡æœ‰éªŒè¯ metadata æ˜¯å¦æœ‰æ•ˆ
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- mode å¯èƒ½æ˜¯æ— æ•ˆå€¼
- engine å¯èƒ½æ— æ³•è¿æ¥
- metadata å¯èƒ½ä¸ºç©º

**å½±å“**:
- è¿è¡Œæ—¶æ‰å‘ç°é”™è¯¯
- é”™è¯¯æ¶ˆæ¯ä¸æ¸…æ™°

**ä¿®å¤å»ºè®®**:
```python
def __init__(self, engine: Engine, metadata, ...):
    # éªŒè¯ mode
    valid_modes = {"safe", "auto", "aggressive", "dry_run"}
    if mode not in valid_modes:
        raise ValueError(
            f"Invalid mode '{mode}'. "
            f"Must be one of {valid_modes}"
        )
    
    # éªŒè¯ engine è¿æ¥
    try:
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
    except Exception as e:
        raise RuntimeError(
            f"Cannot connect to database: {e}"
        )
    
    # éªŒè¯ metadata
    if not metadata or not metadata.tables:
        logger.warning(
            "Metadata has no tables. "
            "This might indicate a configuration issue."
        )
    
    self.engine = engine
    self.metadata = metadata
    self.mode = mode
    ...
```

---

### 6. æ£€æµ‹å™¨ - å¤§å‹æ•°æ®åº“è¶…æ—¶

**ä½ç½®**: `detector.py` (detect_changes)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 21-72)
async def detect_changes(self) -> List[SchemaChange]:
    inspector = await asyncio.to_thread(inspect, self.engine)
    changes = []
    
    # å¯¹æ¯ä¸ªè¡¨è¿›è¡ŒåŒæ­¥æ“ä½œ
    for table_name, table in self.metadata.tables.items():
        if not inspector.has_table(table_name):
            changes.append(self._create_table_change(table_name))
            continue
        
        # æ£€æŸ¥åˆ— - å¯èƒ½å¾ˆæ…¢
        db_columns = {col["name"]: col for col in inspector.get_columns(table_name)}
        orm_columns = {col.name: col for col in table.columns}
        
        # å¯¹æ¯åˆ—è¿›è¡Œæ£€æŸ¥ - æ²¡æœ‰è¶…æ—¶æ§åˆ¶
        for col_name, col in orm_columns.items():
            if col_name not in db_columns:
                changes.append(self._analyze_add_column(table_name, col))
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- å¤§å‹æ•°æ®åº“æœ‰æ•°ç™¾ä¸ªè¡¨
- æ¯ä¸ªè¡¨æœ‰æ•°ç™¾ä¸ªåˆ—
- æ²¡æœ‰è¶…æ—¶æ§åˆ¶
- å¯èƒ½å¯¼è‡´åº”ç”¨å¯åŠ¨è¶…æ—¶

**å½±å“**:
- åº”ç”¨å¯åŠ¨ç¼“æ…¢
- åœ¨å¤§å‹é¡¹ç›®ä¸­æ— æ³•ä½¿ç”¨

**ä¿®å¤å»ºè®®**:
```python
async def detect_changes(self, timeout: int = 60) -> List[SchemaChange]:
    try:
        changes = await asyncio.wait_for(
            self._detect_changes_impl(),
            timeout=timeout
        )
        return changes
    except asyncio.TimeoutError:
        logger.error(
            f"Schema detection timed out after {timeout}s. "
            f"Consider increasing timeout or checking database performance."
        )
        raise

async def _detect_changes_impl(self) -> List[SchemaChange]:
    # åŸæœ‰é€»è¾‘
    ...
```

---

### 7. ç”Ÿæˆå™¨ - SQL æ³¨å…¥é£é™©

**ä½ç½®**: `generator.py` (_generate_sqlite_copy_swap)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 95-130)
def _generate_sqlite_copy_swap(self, change: SchemaChange):
    table_name = change.table
    temp_table_name = f"{table_name}_new_{self._random_string(4)}"
    
    # è¡¨åç›´æ¥æ’å…¥ SQL
    create_temp_sql = str(CreateTable(new_table).compile(self.engine)).strip() + ";"
    copy_sql = f"INSERT INTO {temp_table_name} ({cols_str}) SELECT {cols_str} FROM {table_name};"
    swap_sql = f"DROP TABLE {table_name}; ALTER TABLE {temp_table_name} RENAME TO {table_name};"
```

**æ½œåœ¨é£é™©** ğŸ”´ **é«˜**:
- è™½ç„¶è¡¨åæ¥è‡ª ORMï¼Œä½†ä»ç„¶æœ‰é£é™©
- å¦‚æœè¡¨ååŒ…å«ç‰¹æ®Šå­—ç¬¦ä¼šå¯¼è‡´ SQL é”™è¯¯
- æ²¡æœ‰è½¬ä¹‰

**å½±å“**:
- SQL æ‰§è¡Œå¤±è´¥
- æ•°æ®åº“å¯èƒ½è¢«ç ´å

**ä¿®å¤å»ºè®®**:
```python
def _generate_sqlite_copy_swap(self, change: SchemaChange):
    table_name = change.table
    temp_table_name = f"{table_name}_new_{self._random_string(4)}"
    
    # ä½¿ç”¨ SQLAlchemy çš„æ ‡è¯†ç¬¦è½¬ä¹‰
    from sqlalchemy import identifier
    
    table_ident = identifier(table_name)
    temp_table_ident = identifier(temp_table_name)
    
    # ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
    copy_sql = (
        f"INSERT INTO {temp_table_ident} ({cols_str}) "
        f"SELECT {cols_str} FROM {table_ident};"
    )
```

---

### 8. å­˜å‚¨ - è¡¨ä¸å­˜åœ¨å¤„ç†

**ä½ç½®**: `storage.py` (initialize)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 31-38)
def initialize(self):
    try:
        self.metadata.create_all(self.engine, checkfirst=True)
        logger.debug(f"âœ… Migration history table '{self.TABLE_NAME}' ready")
    except Exception as e:
        logger.error(f"Failed to initialize migration storage: {e}")
        raise
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- å¦‚æœè¡¨åˆ›å»ºå¤±è´¥ï¼Œåç»­æ“ä½œä¼šå¤±è´¥
- æ²¡æœ‰é‡è¯•æœºåˆ¶
- æ²¡æœ‰å›æ»š

**å½±å“**:
- è¿ç§»æ— æ³•è®°å½•
- æ— æ³•è¿½è¸ªå†å²

**ä¿®å¤å»ºè®®**:
```python
def initialize(self, max_retries: int = 3):
    for attempt in range(max_retries):
        try:
            self.metadata.create_all(self.engine, checkfirst=True)
            logger.debug(f"âœ… Migration history table ready")
            return
        except Exception as e:
            if attempt < max_retries - 1:
                logger.warning(
                    f"Failed to initialize storage (attempt {attempt + 1}/{max_retries}): {e}"
                )
                time.sleep(1)
            else:
                logger.error(f"Failed to initialize storage after {max_retries} attempts: {e}")
                raise
```

---

### 9. å¼•æ“ - å¼‚å¸¸æ¢å¤

**ä½ç½®**: `engine.py` (auto_migrate)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 39-89)
async def auto_migrate(self) -> MigrationPlan:
    logger.info("ğŸ”’ Acquiring migration lock...")
    if not await self.lock.acquire():
        logger.warning("â³ Could not acquire lock...")
        return MigrationPlan(migrations=[], status="locked")
    
    try:
        # ... è¿ç§»é€»è¾‘
    except Exception as e:
        logger.error(f"âŒ Migration failed: {e}")
        raise
    finally:
        logger.info("ğŸ”“ Releasing migration lock...")
        await self.lock.release()
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- å¦‚æœ release() ä¹Ÿå¤±è´¥ï¼Œé”æ°¸ä¹…è¢«å ç”¨
- æ²¡æœ‰é‡è¯•æœºåˆ¶
- æ²¡æœ‰å¼ºåˆ¶é‡Šæ”¾

**å½±å“**:
- åç»­è¿ç§»è¢«æ°¸ä¹…é˜»æ­¢
- éœ€è¦æ‰‹åŠ¨æ¸…ç†

**ä¿®å¤å»ºè®®**:
```python
finally:
    logger.info("ğŸ”“ Releasing migration lock...")
    try:
        await self.lock.release()
    except Exception as e:
        logger.error(
            f"Failed to release lock: {e}. "
            f"You may need to manually clean up the lock.",
            exc_info=True
        )
        # ä¸æŠ›å‡ºå¼‚å¸¸ - å·²ç»åœ¨å¼‚å¸¸å¤„ç†ä¸­
```

---

### 10. ç¼“å­˜æ¸…ç† - å†…å­˜æ³„æ¼

**ä½ç½®**: `schema_cache.py` (FileSchemaCacheProvider)

**é—®é¢˜æè¿°**:
```python
# é—®é¢˜ä»£ç  (line 102-111)
async def clear(self) -> bool:
    try:
        for cache_file in self.cache_dir.glob("*.json"):
            cache_file.unlink()
        logger.info("All caches cleared")
        return True
    except Exception as e:
        logger.error(f"Error clearing cache: {e}")
        return False
```

**æ½œåœ¨é£é™©** ğŸŸ¡ **ä¸­**:
- ç¼“å­˜ç›®å½•å¯èƒ½æœ‰æ•°åƒä¸ªæ–‡ä»¶
- glob() ä¼šä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ–‡ä»¶ååˆ°å†…å­˜
- åˆ é™¤æ“ä½œå¯èƒ½å¾ˆæ…¢

**å½±å“**:
- å†…å­˜å ç”¨è¿‡é«˜
- æ¸…ç†æ“ä½œå¯èƒ½è¶…æ—¶

**ä¿®å¤å»ºè®®**:
```python
async def clear(self) -> bool:
    try:
        count = 0
        for cache_file in self.cache_dir.glob("*.json"):
            try:
                cache_file.unlink()
                count += 1
                # æ¯åˆ é™¤ 100 ä¸ªæ–‡ä»¶è®©å‡ºæ§åˆ¶æƒ
                if count % 100 == 0:
                    await asyncio.sleep(0)
            except OSError as e:
                logger.warning(f"Failed to delete {cache_file}: {e}")
        logger.info(f"Cleared {count} cache files")
        return True
    except Exception as e:
        logger.error(f"Error clearing cache: {e}")
        return False
```

---

## ğŸ“Š é—®é¢˜ä¼˜å…ˆçº§çŸ©é˜µ

```
ä¸¥é‡æ€§ vs å½±å“èŒƒå›´

        é«˜å½±å“
          â†‘
    1 â”Œâ”€â”€â”€â”€â”€â” 2
      â”‚ ğŸ”´  â”‚ ğŸ”´
      â”‚ 1,2 â”‚ 4,7
    ä¸­â”œâ”€â”€â”€â”€â”€â”¤
      â”‚ ğŸŸ¡  â”‚ ğŸŸ¡
      â”‚ 3,5 â”‚ 6,8,9,10
    ä½â””â”€â”€â”€â”€â”€â”˜
      ä½    é«˜
      â† æ¦‚ç‡ â†’
```

**ä¼˜å…ˆçº§æ’åº**:
1. ğŸ”´ **ç«‹å³ä¿®å¤** (P0): é—®é¢˜ 1, 2, 7
2. ğŸŸ¡ **æœ¬å‘¨ä¿®å¤** (P1): é—®é¢˜ 3, 4, 5, 6, 8, 9
3. ğŸŸ¢ **åç»­æ”¹è¿›** (P2): é—®é¢˜ 10

---

## âœ… ä¿®å¤è®¡åˆ’

### ç¬¬ä¸€é˜¶æ®µ (ç«‹å³)
- [ ] ä¿®å¤ç¼“å­˜å¹¶å‘è®¿é—® (åŠ é”)
- [ ] ä¿®å¤ MySQL é”è¿æ¥æ³„æ¼ (ä¿å­˜è¿æ¥)
- [ ] ä¿®å¤ SQL æ³¨å…¥é£é™© (ä½¿ç”¨è½¬ä¹‰)

### ç¬¬äºŒé˜¶æ®µ (æœ¬å‘¨)
- [ ] ä¿®å¤æ–‡ä»¶ç¼“å­˜å¹¶å‘å†™å…¥ (åŸå­æ“ä½œ)
- [ ] ä¿®å¤è¿ç§»å­˜å‚¨å¹¶å‘æ’å…¥ (å¼‚å¸¸å¤„ç†)
- [ ] ä¿®å¤å¼•æ“åˆå§‹åŒ–éªŒè¯ (å‚æ•°éªŒè¯)
- [ ] ä¿®å¤æ£€æµ‹å™¨è¶…æ—¶ (æ·»åŠ è¶…æ—¶æ§åˆ¶)
- [ ] ä¿®å¤å­˜å‚¨åˆå§‹åŒ– (é‡è¯•æœºåˆ¶)
- [ ] ä¿®å¤å¼•æ“å¼‚å¸¸æ¢å¤ (æ”¹è¿›é‡Šæ”¾é€»è¾‘)

### ç¬¬ä¸‰é˜¶æ®µ (åç»­)
- [ ] ä¼˜åŒ–ç¼“å­˜æ¸…ç† (æµå¼å¤„ç†)

---

**åˆ†æå®Œæˆ**: 2025-11-29  
**å»ºè®®è¡ŒåŠ¨**: ç«‹å³ä¿®å¤ P0 é—®é¢˜ï¼Œæœ¬å‘¨å®Œæˆ P1 é—®é¢˜
